{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-27 22:34:16.624931: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-27 22:34:17.652668: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers, Sequential, Input\n",
    "from keras.src.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.src.optimizers import Adam, AdamW, RMSprop, SGD\n",
    "from keras.src.utils import image_dataset_from_directory\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = \"resources/Images\"\n",
    "CROPPED_IMAGES_PATH = \"resources/Cropped_Images\"\n",
    "MODELS_PATH = \"models/custom_model\"\n",
    "MODEL_SAVE_PATH = f\"{MODELS_PATH}/custom_model.keras\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimize GPU memory consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_last_generated_models():\n",
    "    shutil.rmtree(MODELS_PATH, ignore_errors=True)\n",
    "    os.makedirs(MODELS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(path, image_size, batch_size, validation_split=0.0, data_type=None):\n",
    "    return image_dataset_from_directory(\n",
    "        path,\n",
    "        labels='inferred',\n",
    "        label_mode='categorical',\n",
    "        class_names=None,\n",
    "        batch_size=batch_size,\n",
    "        image_size=image_size,\n",
    "        seed=42,\n",
    "        validation_split=validation_split,\n",
    "        subset=data_type\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(optimizer, learning_rate):\n",
    "    match optimizer:\n",
    "        case \"adam\":\n",
    "            return Adam(learning_rate=learning_rate)\n",
    "        case \"adamw\":\n",
    "            return AdamW(learning_rate=learning_rate)\n",
    "        case \"rmsprop\":\n",
    "            return RMSprop(learning_rate=learning_rate)\n",
    "        case \"sgd\":\n",
    "            return SGD(learning_rate=learning_rate)\n",
    "        case \"sgdn\":\n",
    "            return SGD(learning_rate=learning_rate, nesterov=True)\n",
    "        case _:\n",
    "            raise ValueError(f\"Unknown optimizer:{optimizer}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, labels_number, kernel_size=(3, 3), number_of_intermediate_layers=3, dropout_rate=0.2,\n",
    "                 optimizer=\"adam\", learning_rate=0.001):\n",
    "    intermediate_layers = Sequential()\n",
    "    \n",
    "    for i in range(1, number_of_intermediate_layers + 1):\n",
    "        intermediate_layers.add(layers.Conv2D(int(32 * math.pow(2, i)), kernel_size, padding='same'))\n",
    "        intermediate_layers.add(layers.BatchNormalization())\n",
    "        intermediate_layers.add(layers.Activation('relu'))\n",
    "        intermediate_layers.add(layers.MaxPooling2D((2, 2)))\n",
    "        \n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "\n",
    "        # Data augmentation layers\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "\n",
    "        # Core layers\n",
    "        intermediate_layers,\n",
    "        \n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(labels_number, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    optimizer = get_optimizer(optimizer, learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(results, hyperparameter_name):\n",
    "    results_df = DataFrame(results)\n",
    "    \n",
    "    display_results_plot(results_df, hyperparameter_name, [\"fitting_time\"], \"fitting_time\")\n",
    "    display_results_plot(results_df, hyperparameter_name, [\"test_accuracy\", \"val_accuracy\"], \"accuracies\",\n",
    "                         ascending=False)\n",
    "    display_results_plot(results_df, hyperparameter_name, [\"test_loss\", \"val_loss\"], \"losses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results_plot(results, hyperparameter_name, metrics, metrics_name, ascending=True):\n",
    "    results.sort_values(metrics[0], ascending=ascending, inplace=True)\n",
    "    performance_plot = (results[metrics + [\"hyperparameters_name\"]]\n",
    "                        .plot(kind=\"line\", x=\"hyperparameters_name\", figsize=(15, 8), rot=0,\n",
    "                              title=f\"Results sorted by {metrics_name}\"))\n",
    "    \n",
    "    performance_plot.title.set_size(20)\n",
    "    performance_plot.set_xticks(range(0, len(results)))\n",
    "    plt.xticks(rotation=90)\n",
    "    performance_plot.set(xlabel=None)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(with_early_stopping):\n",
    "    checkpoint = ModelCheckpoint(MODEL_SAVE_PATH, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "    \n",
    "    return [checkpoint, es] if with_early_stopping else [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_of_model(model, dataset_train, dataset_val, dataset_test, parameters, epoch=100, batch_size=16, with_early_stopping=True):\n",
    "    fitting_start_time = time.time()\n",
    "    model.fit(dataset_train,\n",
    "                        validation_data=dataset_val,\n",
    "                        batch_size=batch_size,\n",
    "                        # epochs=2,\n",
    "                        epochs=epoch,\n",
    "                        callbacks=get_callbacks(with_early_stopping),\n",
    "                        verbose=1)\n",
    "    fitting_time = time.time() - fitting_start_time\n",
    "    \n",
    "    model.load_weights(MODEL_SAVE_PATH)\n",
    "    \n",
    "    val_loss, val_accuracy = model.evaluate(dataset_val, verbose=False)\n",
    "    print(f\"\\nValidation Accuracy:{val_accuracy}.\")\n",
    "    \n",
    "    test_loss, test_accuracy = model.evaluate(dataset_test, verbose=False)\n",
    "    print(f\"\\nTest Accuracy:{test_accuracy}.\\n\")\n",
    "    \n",
    "    return {\n",
    "        \"hyperparameters_name\": hyperparameters[\"name\"],\n",
    "        \"fitting_time\": fitting_time,\n",
    "        \"test_accuracy\": test_accuracy,\n",
    "        \"test_loss\": test_loss,\n",
    "        \"val_accuracy\": val_accuracy,\n",
    "        \"val_loss\": val_loss,\n",
    "        **parameters\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_parameter(sorted_results, parameter_name):\n",
    "    best_parameter = sorted_results[0][parameter_name]\n",
    "    print(f\"Best parameter:{parameter_name.replace(\"_\", \" \")} found:{best_parameter}.\\n\")\n",
    "    return best_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting custom models learning script.\n",
      "\n",
      "Found 20580 files belonging to 120 classes.\n",
      "Using 15435 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-27 22:34:20.312806: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-27 22:34:20.457726: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-27 22:34:20.460492: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-27 22:34:20.464174: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-27 22:34:20.466974: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-27 22:34:20.469589: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-27 22:34:20.596697: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-27 22:34:20.598232: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-27 22:34:20.599563: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-09-27 22:34:20.599663: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-27 22:34:20.601127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6184 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20580 files belonging to 120 classes.\n",
      "Using 5145 files for validation.\n",
      "Found 20580 files belonging to 120 classes.\n",
      "\n",
      "Testing now the parameters:{'number_of_intermediate_layers': 1}.\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-27 22:34:25.026278: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0147 - loss: 4.8014\n",
      "Epoch 1: val_loss improved from inf to 4.63098, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 11ms/step - accuracy: 0.0147 - loss: 4.8014 - val_accuracy: 0.0200 - val_loss: 4.6310\n",
      "Epoch 2/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0228 - loss: 4.6580\n",
      "Epoch 2: val_loss improved from 4.63098 to 4.57826, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 11ms/step - accuracy: 0.0228 - loss: 4.6580 - val_accuracy: 0.0255 - val_loss: 4.5783\n",
      "Epoch 3/100\n",
      "\u001b[1m3858/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0262 - loss: 4.6117\n",
      "Epoch 3: val_loss improved from 4.57826 to 4.56226, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - accuracy: 0.0262 - loss: 4.6117 - val_accuracy: 0.0327 - val_loss: 4.5623\n",
      "Epoch 4/100\n",
      "\u001b[1m3856/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0290 - loss: 4.5895\n",
      "Epoch 4: val_loss improved from 4.56226 to 4.54398, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 11ms/step - accuracy: 0.0290 - loss: 4.5895 - val_accuracy: 0.0373 - val_loss: 4.5440\n",
      "Epoch 5/100\n",
      "\u001b[1m3858/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0301 - loss: 4.5818\n",
      "Epoch 5: val_loss did not improve from 4.54398\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - accuracy: 0.0301 - loss: 4.5818 - val_accuracy: 0.0369 - val_loss: 4.5442\n",
      "Epoch 6/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0351 - loss: 4.5625\n",
      "Epoch 6: val_loss improved from 4.54398 to 4.54149, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - accuracy: 0.0351 - loss: 4.5625 - val_accuracy: 0.0344 - val_loss: 4.5415\n",
      "Epoch 7/100\n",
      "\u001b[1m3856/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0338 - loss: 4.5708\n",
      "Epoch 7: val_loss improved from 4.54149 to 4.52794, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - accuracy: 0.0338 - loss: 4.5707 - val_accuracy: 0.0369 - val_loss: 4.5279\n",
      "Epoch 8/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0333 - loss: 4.5421\n",
      "Epoch 8: val_loss improved from 4.52794 to 4.49945, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - accuracy: 0.0333 - loss: 4.5422 - val_accuracy: 0.0430 - val_loss: 4.4995\n",
      "Epoch 9/100\n",
      "\u001b[1m3855/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0390 - loss: 4.5305\n",
      "Epoch 9: val_loss did not improve from 4.49945\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - accuracy: 0.0390 - loss: 4.5305 - val_accuracy: 0.0336 - val_loss: 4.5248\n",
      "Epoch 10/100\n",
      "\u001b[1m3858/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0363 - loss: 4.5257\n",
      "Epoch 10: val_loss did not improve from 4.49945\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - accuracy: 0.0363 - loss: 4.5257 - val_accuracy: 0.0363 - val_loss: 4.5051\n",
      "Epoch 11/100\n",
      "\u001b[1m3855/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0392 - loss: 4.5165\n",
      "Epoch 11: val_loss improved from 4.49945 to 4.47454, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - accuracy: 0.0392 - loss: 4.5165 - val_accuracy: 0.0455 - val_loss: 4.4745\n",
      "Epoch 12/100\n",
      "\u001b[1m3854/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0437 - loss: 4.5100\n",
      "Epoch 12: val_loss did not improve from 4.47454\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - accuracy: 0.0436 - loss: 4.5100 - val_accuracy: 0.0350 - val_loss: 4.5364\n",
      "Epoch 13/100\n",
      "\u001b[1m3855/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0415 - loss: 4.4857\n",
      "Epoch 13: val_loss did not improve from 4.47454\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - accuracy: 0.0415 - loss: 4.4857 - val_accuracy: 0.0348 - val_loss: 4.5423\n",
      "Epoch 14/100\n",
      "\u001b[1m3854/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0406 - loss: 4.4928\n",
      "Epoch 14: val_loss did not improve from 4.47454\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - accuracy: 0.0406 - loss: 4.4928 - val_accuracy: 0.0220 - val_loss: 4.6894\n",
      "Epoch 15/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0463 - loss: 4.4870\n",
      "Epoch 15: val_loss did not improve from 4.47454\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - accuracy: 0.0463 - loss: 4.4870 - val_accuracy: 0.0461 - val_loss: 4.4794\n",
      "Epoch 16/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0401 - loss: 4.4786\n",
      "Epoch 16: val_loss did not improve from 4.47454\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - accuracy: 0.0401 - loss: 4.4786 - val_accuracy: 0.0274 - val_loss: 4.6081\n",
      "Epoch 17/100\n",
      "\u001b[1m3854/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0431 - loss: 4.4632\n",
      "Epoch 17: val_loss did not improve from 4.47454\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - accuracy: 0.0431 - loss: 4.4632 - val_accuracy: 0.0404 - val_loss: 4.5110\n",
      "Epoch 18/100\n",
      "\u001b[1m3855/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0466 - loss: 4.4700\n",
      "Epoch 18: val_loss improved from 4.47454 to 4.44315, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - accuracy: 0.0466 - loss: 4.4700 - val_accuracy: 0.0468 - val_loss: 4.4431\n",
      "Epoch 19/100\n",
      "\u001b[1m3854/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0433 - loss: 4.4624\n",
      "Epoch 19: val_loss did not improve from 4.44315\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - accuracy: 0.0433 - loss: 4.4625 - val_accuracy: 0.0268 - val_loss: 4.7294\n",
      "Epoch 20/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0484 - loss: 4.4589\n",
      "Epoch 20: val_loss did not improve from 4.44315\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - accuracy: 0.0484 - loss: 4.4589 - val_accuracy: 0.0470 - val_loss: 4.4832\n",
      "Epoch 21/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0432 - loss: 4.4591\n",
      "Epoch 21: val_loss did not improve from 4.44315\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - accuracy: 0.0432 - loss: 4.4591 - val_accuracy: 0.0356 - val_loss: 4.5582\n",
      "Epoch 22/100\n",
      "\u001b[1m3856/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0490 - loss: 4.4479\n",
      "Epoch 22: val_loss did not improve from 4.44315\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - accuracy: 0.0490 - loss: 4.4479 - val_accuracy: 0.0268 - val_loss: 4.7331\n",
      "Epoch 23/100\n",
      "\u001b[1m3857/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0469 - loss: 4.4500\n",
      "Epoch 23: val_loss did not improve from 4.44315\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - accuracy: 0.0469 - loss: 4.4500 - val_accuracy: 0.0270 - val_loss: 4.8406\n",
      "Epoch 24/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0452 - loss: 4.4505\n",
      "Epoch 24: val_loss did not improve from 4.44315\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - accuracy: 0.0452 - loss: 4.4505 - val_accuracy: 0.0328 - val_loss: 4.6071\n",
      "Epoch 25/100\n",
      "\u001b[1m3857/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0469 - loss: 4.4593\n",
      "Epoch 25: val_loss did not improve from 4.44315\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - accuracy: 0.0469 - loss: 4.4593 - val_accuracy: 0.0488 - val_loss: 4.4636\n",
      "Epoch 26/100\n",
      "\u001b[1m3856/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0489 - loss: 4.4345\n",
      "Epoch 26: val_loss did not improve from 4.44315\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - accuracy: 0.0489 - loss: 4.4345 - val_accuracy: 0.0346 - val_loss: 4.6297\n",
      "Epoch 27/100\n",
      "\u001b[1m3854/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0484 - loss: 4.4372\n",
      "Epoch 27: val_loss did not improve from 4.44315\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - accuracy: 0.0484 - loss: 4.4372 - val_accuracy: 0.0309 - val_loss: 4.6308\n",
      "Epoch 28/100\n",
      "\u001b[1m3854/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0421 - loss: 4.4372\n",
      "Epoch 28: val_loss did not improve from 4.44315\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - accuracy: 0.0421 - loss: 4.4372 - val_accuracy: 0.0284 - val_loss: 4.7630\n",
      "Epoch 28: early stopping\n",
      "\n",
      "Validation Accuracy:0.04684159532189369.\n",
      "\n",
      "Test Accuracy:0.05291545018553734.\n",
      "\n",
      "\n",
      "Testing now the parameters:{'number_of_intermediate_layers': 2}.\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0209 - loss: 4.7935\n",
      "Epoch 1: val_loss improved from inf to 4.62007, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 17ms/step - accuracy: 0.0209 - loss: 4.7935 - val_accuracy: 0.0253 - val_loss: 4.6201\n",
      "Epoch 2/100\n",
      "\u001b[1m3857/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0306 - loss: 4.5626\n",
      "Epoch 2: val_loss improved from 4.62007 to 4.50512, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.0306 - loss: 4.5626 - val_accuracy: 0.0336 - val_loss: 4.5051\n",
      "Epoch 3/100\n",
      "\u001b[1m3856/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0346 - loss: 4.4948\n",
      "Epoch 3: val_loss improved from 4.50512 to 4.47462, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.0346 - loss: 4.4948 - val_accuracy: 0.0406 - val_loss: 4.4746\n",
      "Epoch 4/100\n",
      "\u001b[1m3856/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0453 - loss: 4.4518\n",
      "Epoch 4: val_loss improved from 4.47462 to 4.41257, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.0453 - loss: 4.4518 - val_accuracy: 0.0455 - val_loss: 4.4126\n",
      "Epoch 5/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0475 - loss: 4.4149\n",
      "Epoch 5: val_loss did not improve from 4.41257\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.0475 - loss: 4.4149 - val_accuracy: 0.0344 - val_loss: 4.5238\n",
      "Epoch 6/100\n",
      "\u001b[1m3858/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0485 - loss: 4.3795\n",
      "Epoch 6: val_loss improved from 4.41257 to 4.39927, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.0485 - loss: 4.3795 - val_accuracy: 0.0463 - val_loss: 4.3993\n",
      "Epoch 7/100\n",
      "\u001b[1m3858/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0537 - loss: 4.3431\n",
      "Epoch 7: val_loss improved from 4.39927 to 4.36998, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.0537 - loss: 4.3431 - val_accuracy: 0.0472 - val_loss: 4.3700\n",
      "Epoch 8/100\n",
      "\u001b[1m3856/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0570 - loss: 4.3114\n",
      "Epoch 8: val_loss improved from 4.36998 to 4.31003, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.0570 - loss: 4.3114 - val_accuracy: 0.0548 - val_loss: 4.3100\n",
      "Epoch 9/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0623 - loss: 4.2932\n",
      "Epoch 9: val_loss did not improve from 4.31003\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.0623 - loss: 4.2932 - val_accuracy: 0.0457 - val_loss: 4.4661\n",
      "Epoch 10/100\n",
      "\u001b[1m3857/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0625 - loss: 4.2767\n",
      "Epoch 10: val_loss did not improve from 4.31003\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.0625 - loss: 4.2767 - val_accuracy: 0.0608 - val_loss: 4.3104\n",
      "Epoch 11/100\n",
      "\u001b[1m3857/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0678 - loss: 4.2556\n",
      "Epoch 11: val_loss did not improve from 4.31003\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.0678 - loss: 4.2556 - val_accuracy: 0.0486 - val_loss: 4.4312\n",
      "Epoch 12/100\n",
      "\u001b[1m3858/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0680 - loss: 4.2358\n",
      "Epoch 12: val_loss did not improve from 4.31003\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.0680 - loss: 4.2358 - val_accuracy: 0.0521 - val_loss: 4.4105\n",
      "Epoch 13/100\n",
      "\u001b[1m3857/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0725 - loss: 4.2169\n",
      "Epoch 13: val_loss did not improve from 4.31003\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.0725 - loss: 4.2168 - val_accuracy: 0.0525 - val_loss: 4.3747\n",
      "Epoch 14/100\n",
      "\u001b[1m3858/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0732 - loss: 4.1922\n",
      "Epoch 14: val_loss did not improve from 4.31003\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.0732 - loss: 4.1922 - val_accuracy: 0.0435 - val_loss: 4.4150\n",
      "Epoch 15/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0774 - loss: 4.1775\n",
      "Epoch 15: val_loss did not improve from 4.31003\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.0774 - loss: 4.1775 - val_accuracy: 0.0505 - val_loss: 4.4092\n",
      "Epoch 16/100\n",
      "\u001b[1m3857/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0781 - loss: 4.1651\n",
      "Epoch 16: val_loss improved from 4.31003 to 4.23709, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.0781 - loss: 4.1651 - val_accuracy: 0.0682 - val_loss: 4.2371\n",
      "Epoch 17/100\n",
      "\u001b[1m3857/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0775 - loss: 4.1411\n",
      "Epoch 17: val_loss improved from 4.23709 to 4.21157, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.0775 - loss: 4.1411 - val_accuracy: 0.0748 - val_loss: 4.2116\n",
      "Epoch 18/100\n",
      "\u001b[1m3858/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0819 - loss: 4.1312\n",
      "Epoch 18: val_loss did not improve from 4.21157\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.0819 - loss: 4.1312 - val_accuracy: 0.0604 - val_loss: 4.3512\n",
      "Epoch 19/100\n",
      "\u001b[1m3858/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0786 - loss: 4.1159\n",
      "Epoch 19: val_loss improved from 4.21157 to 4.18738, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.0786 - loss: 4.1159 - val_accuracy: 0.0791 - val_loss: 4.1874\n",
      "Epoch 20/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0797 - loss: 4.1022\n",
      "Epoch 20: val_loss improved from 4.18738 to 4.11891, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.0797 - loss: 4.1022 - val_accuracy: 0.0857 - val_loss: 4.1189\n",
      "Epoch 21/100\n",
      "\u001b[1m3857/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0872 - loss: 4.0759\n",
      "Epoch 21: val_loss did not improve from 4.11891\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.0872 - loss: 4.0759 - val_accuracy: 0.0688 - val_loss: 4.2667\n",
      "Epoch 22/100\n",
      "\u001b[1m3858/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0915 - loss: 4.0701\n",
      "Epoch 22: val_loss did not improve from 4.11891\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.0915 - loss: 4.0701 - val_accuracy: 0.0566 - val_loss: 4.3992\n",
      "Epoch 23/100\n",
      "\u001b[1m3857/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0914 - loss: 4.0625\n",
      "Epoch 23: val_loss did not improve from 4.11891\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.0914 - loss: 4.0625 - val_accuracy: 0.0593 - val_loss: 4.4879\n",
      "Epoch 24/100\n",
      "\u001b[1m3856/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0942 - loss: 4.0452\n",
      "Epoch 24: val_loss did not improve from 4.11891\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.0942 - loss: 4.0452 - val_accuracy: 0.0717 - val_loss: 4.2963\n",
      "Epoch 25/100\n",
      "\u001b[1m3858/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0941 - loss: 4.0361\n",
      "Epoch 25: val_loss did not improve from 4.11891\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.0941 - loss: 4.0361 - val_accuracy: 0.0706 - val_loss: 4.2564\n",
      "Epoch 26/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0937 - loss: 4.0241\n",
      "Epoch 26: val_loss did not improve from 4.11891\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.0937 - loss: 4.0241 - val_accuracy: 0.0566 - val_loss: 4.6288\n",
      "Epoch 27/100\n",
      "\u001b[1m3858/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1001 - loss: 4.0127\n",
      "Epoch 27: val_loss improved from 4.11891 to 4.10406, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.1001 - loss: 4.0127 - val_accuracy: 0.0847 - val_loss: 4.1041\n",
      "Epoch 28/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1002 - loss: 3.9967\n",
      "Epoch 28: val_loss did not improve from 4.10406\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.1002 - loss: 3.9967 - val_accuracy: 0.0853 - val_loss: 4.1253\n",
      "Epoch 29/100\n",
      "\u001b[1m3858/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0997 - loss: 3.9818\n",
      "Epoch 29: val_loss did not improve from 4.10406\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.0997 - loss: 3.9818 - val_accuracy: 0.0663 - val_loss: 4.4111\n",
      "Epoch 30/100\n",
      "\u001b[1m3858/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1034 - loss: 3.9751\n",
      "Epoch 30: val_loss improved from 4.10406 to 4.02267, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.1034 - loss: 3.9751 - val_accuracy: 0.1057 - val_loss: 4.0227\n",
      "Epoch 31/100\n",
      "\u001b[1m3858/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1071 - loss: 3.9638\n",
      "Epoch 31: val_loss did not improve from 4.02267\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.1071 - loss: 3.9638 - val_accuracy: 0.0935 - val_loss: 4.0588\n",
      "Epoch 32/100\n",
      "\u001b[1m3856/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1045 - loss: 3.9422\n",
      "Epoch 32: val_loss did not improve from 4.02267\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.1045 - loss: 3.9422 - val_accuracy: 0.0921 - val_loss: 4.0904\n",
      "Epoch 33/100\n",
      "\u001b[1m3858/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1050 - loss: 3.9358\n",
      "Epoch 33: val_loss did not improve from 4.02267\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.1050 - loss: 3.9358 - val_accuracy: 0.0752 - val_loss: 4.2581\n",
      "Epoch 34/100\n",
      "\u001b[1m3856/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1076 - loss: 3.9291\n",
      "Epoch 34: val_loss did not improve from 4.02267\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.1076 - loss: 3.9291 - val_accuracy: 0.0904 - val_loss: 4.1039\n",
      "Epoch 35/100\n",
      "\u001b[1m3857/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1092 - loss: 3.9153\n",
      "Epoch 35: val_loss did not improve from 4.02267\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.1092 - loss: 3.9153 - val_accuracy: 0.0647 - val_loss: 4.3279\n",
      "Epoch 36/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1119 - loss: 3.9183\n",
      "Epoch 36: val_loss did not improve from 4.02267\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.1119 - loss: 3.9183 - val_accuracy: 0.0948 - val_loss: 4.0815\n",
      "Epoch 37/100\n",
      "\u001b[1m3856/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1105 - loss: 3.9019\n",
      "Epoch 37: val_loss did not improve from 4.02267\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.1105 - loss: 3.9019 - val_accuracy: 0.0719 - val_loss: 4.3038\n",
      "Epoch 38/100\n",
      "\u001b[1m3856/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1158 - loss: 3.8952\n",
      "Epoch 38: val_loss did not improve from 4.02267\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.1158 - loss: 3.8952 - val_accuracy: 0.0661 - val_loss: 4.3887\n",
      "Epoch 39/100\n",
      "\u001b[1m3856/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1144 - loss: 3.8698\n",
      "Epoch 39: val_loss did not improve from 4.02267\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.1144 - loss: 3.8698 - val_accuracy: 0.0867 - val_loss: 4.1671\n",
      "Epoch 40/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1165 - loss: 3.8662\n",
      "Epoch 40: val_loss did not improve from 4.02267\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 17ms/step - accuracy: 0.1165 - loss: 3.8662 - val_accuracy: 0.0882 - val_loss: 4.1690\n",
      "Epoch 40: early stopping\n",
      "\n",
      "Validation Accuracy:0.105733722448349.\n",
      "\n",
      "Test Accuracy:0.1130223497748375.\n",
      "\n",
      "\n",
      "Testing now the parameters:{'number_of_intermediate_layers': 3}.\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0207 - loss: 4.8342\n",
      "Epoch 1: val_loss improved from inf to 5.26737, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 22ms/step - accuracy: 0.0207 - loss: 4.8342 - val_accuracy: 0.0130 - val_loss: 5.2674\n",
      "Epoch 2/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0311 - loss: 4.5255\n",
      "Epoch 2: val_loss improved from 5.26737 to 4.65240, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.0311 - loss: 4.5255 - val_accuracy: 0.0260 - val_loss: 4.6524\n",
      "Epoch 3/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0423 - loss: 4.4201\n",
      "Epoch 3: val_loss did not improve from 4.65240\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.0423 - loss: 4.4201 - val_accuracy: 0.0307 - val_loss: 4.7822\n",
      "Epoch 4/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0508 - loss: 4.3298\n",
      "Epoch 4: val_loss did not improve from 4.65240\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.0508 - loss: 4.3298 - val_accuracy: 0.0270 - val_loss: 4.9286\n",
      "Epoch 5/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0632 - loss: 4.2295\n",
      "Epoch 5: val_loss did not improve from 4.65240\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.0632 - loss: 4.2295 - val_accuracy: 0.0410 - val_loss: 4.7438\n",
      "Epoch 6/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0723 - loss: 4.1478\n",
      "Epoch 6: val_loss improved from 4.65240 to 4.05519, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.0723 - loss: 4.1478 - val_accuracy: 0.0927 - val_loss: 4.0552\n",
      "Epoch 7/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0802 - loss: 4.0697\n",
      "Epoch 7: val_loss did not improve from 4.05519\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.0802 - loss: 4.0697 - val_accuracy: 0.0830 - val_loss: 4.1643\n",
      "Epoch 8/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0923 - loss: 3.9898\n",
      "Epoch 8: val_loss did not improve from 4.05519\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.0923 - loss: 3.9898 - val_accuracy: 0.0721 - val_loss: 4.2995\n",
      "Epoch 9/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1052 - loss: 3.9069\n",
      "Epoch 9: val_loss did not improve from 4.05519\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.1052 - loss: 3.9069 - val_accuracy: 0.0748 - val_loss: 4.2400\n",
      "Epoch 10/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1157 - loss: 3.8553\n",
      "Epoch 10: val_loss did not improve from 4.05519\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.1157 - loss: 3.8553 - val_accuracy: 0.0651 - val_loss: 4.4821\n",
      "Epoch 11/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1214 - loss: 3.7882\n",
      "Epoch 11: val_loss did not improve from 4.05519\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.1214 - loss: 3.7882 - val_accuracy: 0.0663 - val_loss: 4.4351\n",
      "Epoch 12/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1259 - loss: 3.7236\n",
      "Epoch 12: val_loss improved from 4.05519 to 3.96491, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.1259 - loss: 3.7236 - val_accuracy: 0.1055 - val_loss: 3.9649\n",
      "Epoch 13/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1383 - loss: 3.6742\n",
      "Epoch 13: val_loss did not improve from 3.96491\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.1383 - loss: 3.6742 - val_accuracy: 0.0832 - val_loss: 4.1901\n",
      "Epoch 14/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1421 - loss: 3.6431\n",
      "Epoch 14: val_loss did not improve from 3.96491\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.1421 - loss: 3.6431 - val_accuracy: 0.0958 - val_loss: 4.0945\n",
      "Epoch 15/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1504 - loss: 3.5964\n",
      "Epoch 15: val_loss did not improve from 3.96491\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.1504 - loss: 3.5964 - val_accuracy: 0.0968 - val_loss: 4.1033\n",
      "Epoch 16/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1640 - loss: 3.5573\n",
      "Epoch 16: val_loss did not improve from 3.96491\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.1640 - loss: 3.5573 - val_accuracy: 0.1067 - val_loss: 3.9884\n",
      "Epoch 17/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1668 - loss: 3.5205\n",
      "Epoch 17: val_loss did not improve from 3.96491\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.1668 - loss: 3.5205 - val_accuracy: 0.1088 - val_loss: 4.0388\n",
      "Epoch 18/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1750 - loss: 3.4744\n",
      "Epoch 18: val_loss improved from 3.96491 to 3.85745, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.1750 - loss: 3.4744 - val_accuracy: 0.1224 - val_loss: 3.8575\n",
      "Epoch 19/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1719 - loss: 3.4564\n",
      "Epoch 19: val_loss did not improve from 3.85745\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.1719 - loss: 3.4564 - val_accuracy: 0.1203 - val_loss: 3.8816\n",
      "Epoch 20/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1790 - loss: 3.4224\n",
      "Epoch 20: val_loss did not improve from 3.85745\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.1790 - loss: 3.4224 - val_accuracy: 0.1151 - val_loss: 3.9113\n",
      "Epoch 21/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1867 - loss: 3.4008\n",
      "Epoch 21: val_loss improved from 3.85745 to 3.81405, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.1867 - loss: 3.4008 - val_accuracy: 0.1345 - val_loss: 3.8141\n",
      "Epoch 22/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1900 - loss: 3.3641\n",
      "Epoch 22: val_loss did not improve from 3.81405\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.1900 - loss: 3.3641 - val_accuracy: 0.1267 - val_loss: 3.8623\n",
      "Epoch 23/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1925 - loss: 3.3473\n",
      "Epoch 23: val_loss did not improve from 3.81405\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.1925 - loss: 3.3473 - val_accuracy: 0.1063 - val_loss: 3.9816\n",
      "Epoch 24/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2015 - loss: 3.3207\n",
      "Epoch 24: val_loss improved from 3.81405 to 3.63149, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.2015 - loss: 3.3207 - val_accuracy: 0.1528 - val_loss: 3.6315\n",
      "Epoch 25/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2047 - loss: 3.2945\n",
      "Epoch 25: val_loss improved from 3.63149 to 3.62833, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.2047 - loss: 3.2945 - val_accuracy: 0.1687 - val_loss: 3.6283\n",
      "Epoch 26/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2044 - loss: 3.2794\n",
      "Epoch 26: val_loss did not improve from 3.62833\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.2044 - loss: 3.2794 - val_accuracy: 0.1050 - val_loss: 4.1358\n",
      "Epoch 27/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2102 - loss: 3.2320\n",
      "Epoch 27: val_loss improved from 3.62833 to 3.60827, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.2102 - loss: 3.2320 - val_accuracy: 0.1637 - val_loss: 3.6083\n",
      "Epoch 28/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2085 - loss: 3.2244\n",
      "Epoch 28: val_loss did not improve from 3.60827\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.2085 - loss: 3.2244 - val_accuracy: 0.1156 - val_loss: 3.9749\n",
      "Epoch 29/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2184 - loss: 3.2129\n",
      "Epoch 29: val_loss improved from 3.60827 to 3.44350, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.2184 - loss: 3.2129 - val_accuracy: 0.1920 - val_loss: 3.4435\n",
      "Epoch 30/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2204 - loss: 3.1790\n",
      "Epoch 30: val_loss did not improve from 3.44350\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.2204 - loss: 3.1790 - val_accuracy: 0.1506 - val_loss: 3.7115\n",
      "Epoch 31/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2251 - loss: 3.1676\n",
      "Epoch 31: val_loss did not improve from 3.44350\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.2251 - loss: 3.1676 - val_accuracy: 0.1506 - val_loss: 3.8560\n",
      "Epoch 32/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2235 - loss: 3.1601\n",
      "Epoch 32: val_loss did not improve from 3.44350\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.2235 - loss: 3.1601 - val_accuracy: 0.1431 - val_loss: 3.7875\n",
      "Epoch 33/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2260 - loss: 3.1332\n",
      "Epoch 33: val_loss did not improve from 3.44350\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.2260 - loss: 3.1332 - val_accuracy: 0.0943 - val_loss: 4.5607\n",
      "Epoch 34/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2327 - loss: 3.1319\n",
      "Epoch 34: val_loss improved from 3.44350 to 3.35745, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.2327 - loss: 3.1319 - val_accuracy: 0.2097 - val_loss: 3.3574\n",
      "Epoch 35/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2318 - loss: 3.1234\n",
      "Epoch 35: val_loss did not improve from 3.35745\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.2318 - loss: 3.1234 - val_accuracy: 0.2062 - val_loss: 3.3624\n",
      "Epoch 36/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2367 - loss: 3.0999\n",
      "Epoch 36: val_loss did not improve from 3.35745\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.2367 - loss: 3.0999 - val_accuracy: 0.1755 - val_loss: 3.5453\n",
      "Epoch 37/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2432 - loss: 3.0657\n",
      "Epoch 37: val_loss did not improve from 3.35745\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.2432 - loss: 3.0657 - val_accuracy: 0.0991 - val_loss: 4.5872\n",
      "Epoch 38/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2458 - loss: 3.0604\n",
      "Epoch 38: val_loss did not improve from 3.35745\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.2458 - loss: 3.0604 - val_accuracy: 0.1946 - val_loss: 3.4466\n",
      "Epoch 39/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2491 - loss: 3.0364\n",
      "Epoch 39: val_loss did not improve from 3.35745\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.2491 - loss: 3.0364 - val_accuracy: 0.1819 - val_loss: 3.5533\n",
      "Epoch 40/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2505 - loss: 3.0338\n",
      "Epoch 40: val_loss did not improve from 3.35745\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.2505 - loss: 3.0338 - val_accuracy: 0.1771 - val_loss: 3.5194\n",
      "Epoch 41/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2496 - loss: 3.0236\n",
      "Epoch 41: val_loss improved from 3.35745 to 3.22004, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.2496 - loss: 3.0236 - val_accuracy: 0.2315 - val_loss: 3.2200\n",
      "Epoch 42/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2569 - loss: 3.0029\n",
      "Epoch 42: val_loss did not improve from 3.22004\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.2569 - loss: 3.0029 - val_accuracy: 0.1565 - val_loss: 3.6970\n",
      "Epoch 43/100\n",
      "\u001b[1m3857/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2553 - loss: 2.9729\n",
      "Epoch 43: val_loss did not improve from 3.22004\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.2553 - loss: 2.9729 - val_accuracy: 0.1856 - val_loss: 3.5000\n",
      "Epoch 44/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2599 - loss: 2.9761\n",
      "Epoch 44: val_loss did not improve from 3.22004\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.2599 - loss: 2.9761 - val_accuracy: 0.1881 - val_loss: 3.5453\n",
      "Epoch 45/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2625 - loss: 2.9570\n",
      "Epoch 45: val_loss did not improve from 3.22004\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.2625 - loss: 2.9570 - val_accuracy: 0.2140 - val_loss: 3.3739\n",
      "Epoch 46/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2614 - loss: 2.9408\n",
      "Epoch 46: val_loss did not improve from 3.22004\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.2614 - loss: 2.9408 - val_accuracy: 0.2295 - val_loss: 3.2919\n",
      "Epoch 47/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2660 - loss: 2.9329\n",
      "Epoch 47: val_loss did not improve from 3.22004\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.2660 - loss: 2.9329 - val_accuracy: 0.1621 - val_loss: 3.7330\n",
      "Epoch 48/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2695 - loss: 2.9219\n",
      "Epoch 48: val_loss did not improve from 3.22004\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.2695 - loss: 2.9219 - val_accuracy: 0.2237 - val_loss: 3.3166\n",
      "Epoch 49/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2746 - loss: 2.9053\n",
      "Epoch 49: val_loss did not improve from 3.22004\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.2746 - loss: 2.9053 - val_accuracy: 0.2290 - val_loss: 3.2992\n",
      "Epoch 50/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2790 - loss: 2.9020\n",
      "Epoch 50: val_loss did not improve from 3.22004\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 22ms/step - accuracy: 0.2790 - loss: 2.9020 - val_accuracy: 0.2225 - val_loss: 3.3324\n",
      "Epoch 51/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2796 - loss: 2.8682\n",
      "Epoch 51: val_loss did not improve from 3.22004\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 22ms/step - accuracy: 0.2796 - loss: 2.8682 - val_accuracy: 0.2198 - val_loss: 3.3306\n",
      "Epoch 51: early stopping\n",
      "\n",
      "Validation Accuracy:0.23148688673973083.\n",
      "\n",
      "Test Accuracy:0.2687074840068817.\n",
      "\n",
      "\n",
      "Testing now the parameters:{'number_of_intermediate_layers': 4}.\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0183 - loss: 4.9653\n",
      "Epoch 1: val_loss improved from inf to 4.53686, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 25ms/step - accuracy: 0.0184 - loss: 4.9652 - val_accuracy: 0.0336 - val_loss: 4.5369\n",
      "Epoch 2/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0328 - loss: 4.5207\n",
      "Epoch 2: val_loss did not improve from 4.53686\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.0328 - loss: 4.5207 - val_accuracy: 0.0253 - val_loss: 4.6854\n",
      "Epoch 3/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0476 - loss: 4.3422\n",
      "Epoch 3: val_loss improved from 4.53686 to 4.34319, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.0476 - loss: 4.3422 - val_accuracy: 0.0488 - val_loss: 4.3432\n",
      "Epoch 4/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0708 - loss: 4.1493\n",
      "Epoch 4: val_loss improved from 4.34319 to 4.30763, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.0708 - loss: 4.1493 - val_accuracy: 0.0647 - val_loss: 4.3076\n",
      "Epoch 5/100\n",
      "\u001b[1m3858/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0984 - loss: 3.9589\n",
      "Epoch 5: val_loss improved from 4.30763 to 4.11201, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.0984 - loss: 3.9588 - val_accuracy: 0.0715 - val_loss: 4.1120\n",
      "Epoch 6/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1178 - loss: 3.7733\n",
      "Epoch 6: val_loss improved from 4.11201 to 3.81991, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.1178 - loss: 3.7733 - val_accuracy: 0.1153 - val_loss: 3.8199\n",
      "Epoch 7/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1370 - loss: 3.6415\n",
      "Epoch 7: val_loss did not improve from 3.81991\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.1370 - loss: 3.6415 - val_accuracy: 0.1092 - val_loss: 3.8640\n",
      "Epoch 8/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1563 - loss: 3.5228\n",
      "Epoch 8: val_loss did not improve from 3.81991\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.1563 - loss: 3.5228 - val_accuracy: 0.1046 - val_loss: 3.8978\n",
      "Epoch 9/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1761 - loss: 3.4211\n",
      "Epoch 9: val_loss improved from 3.81991 to 3.70072, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.1761 - loss: 3.4211 - val_accuracy: 0.1413 - val_loss: 3.7007\n",
      "Epoch 10/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1913 - loss: 3.3166\n",
      "Epoch 10: val_loss improved from 3.70072 to 3.35136, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.1913 - loss: 3.3166 - val_accuracy: 0.1975 - val_loss: 3.3514\n",
      "Epoch 11/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2045 - loss: 3.2329\n",
      "Epoch 11: val_loss did not improve from 3.35136\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.2045 - loss: 3.2329 - val_accuracy: 0.1922 - val_loss: 3.4399\n",
      "Epoch 12/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2181 - loss: 3.1513\n",
      "Epoch 12: val_loss did not improve from 3.35136\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.2181 - loss: 3.1513 - val_accuracy: 0.1965 - val_loss: 3.4319\n",
      "Epoch 13/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2350 - loss: 3.0919\n",
      "Epoch 13: val_loss improved from 3.35136 to 3.34983, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.2350 - loss: 3.0919 - val_accuracy: 0.2095 - val_loss: 3.3498\n",
      "Epoch 14/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2438 - loss: 3.0282\n",
      "Epoch 14: val_loss did not improve from 3.34983\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.2438 - loss: 3.0282 - val_accuracy: 0.1967 - val_loss: 3.5310\n",
      "Epoch 15/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2510 - loss: 2.9610\n",
      "Epoch 15: val_loss improved from 3.34983 to 2.98975, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.2510 - loss: 2.9610 - val_accuracy: 0.2568 - val_loss: 2.9898\n",
      "Epoch 16/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2696 - loss: 2.8987\n",
      "Epoch 16: val_loss did not improve from 2.98975\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.2696 - loss: 2.8987 - val_accuracy: 0.2369 - val_loss: 3.1404\n",
      "Epoch 17/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2777 - loss: 2.8460\n",
      "Epoch 17: val_loss did not improve from 2.98975\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.2777 - loss: 2.8460 - val_accuracy: 0.2358 - val_loss: 3.1589\n",
      "Epoch 18/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2976 - loss: 2.7789\n",
      "Epoch 18: val_loss did not improve from 2.98975\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.2976 - loss: 2.7789 - val_accuracy: 0.2321 - val_loss: 3.2107\n",
      "Epoch 19/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3013 - loss: 2.7302\n",
      "Epoch 19: val_loss did not improve from 2.98975\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.3013 - loss: 2.7302 - val_accuracy: 0.2047 - val_loss: 3.6717\n",
      "Epoch 20/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3146 - loss: 2.6785\n",
      "Epoch 20: val_loss did not improve from 2.98975\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.3146 - loss: 2.6785 - val_accuracy: 0.2766 - val_loss: 3.0040\n",
      "Epoch 21/100\n",
      "\u001b[1m3858/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3253 - loss: 2.6438\n",
      "Epoch 21: val_loss did not improve from 2.98975\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.3253 - loss: 2.6438 - val_accuracy: 0.2338 - val_loss: 3.3451\n",
      "Epoch 22/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3283 - loss: 2.5863\n",
      "Epoch 22: val_loss improved from 2.98975 to 2.95641, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.3283 - loss: 2.5863 - val_accuracy: 0.2801 - val_loss: 2.9564\n",
      "Epoch 23/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3430 - loss: 2.5395\n",
      "Epoch 23: val_loss improved from 2.95641 to 2.71531, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 25ms/step - accuracy: 0.3430 - loss: 2.5395 - val_accuracy: 0.3081 - val_loss: 2.7153\n",
      "Epoch 24/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3484 - loss: 2.4851\n",
      "Epoch 24: val_loss did not improve from 2.71531\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.3484 - loss: 2.4851 - val_accuracy: 0.2914 - val_loss: 2.7969\n",
      "Epoch 25/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3511 - loss: 2.4704\n",
      "Epoch 25: val_loss improved from 2.71531 to 2.67759, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.3511 - loss: 2.4704 - val_accuracy: 0.3291 - val_loss: 2.6776\n",
      "Epoch 26/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3678 - loss: 2.4261\n",
      "Epoch 26: val_loss improved from 2.67759 to 2.60021, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 25ms/step - accuracy: 0.3678 - loss: 2.4261 - val_accuracy: 0.3471 - val_loss: 2.6002\n",
      "Epoch 27/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3770 - loss: 2.3839\n",
      "Epoch 27: val_loss did not improve from 2.60021\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.3770 - loss: 2.3839 - val_accuracy: 0.3232 - val_loss: 2.7189\n",
      "Epoch 28/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3806 - loss: 2.3427\n",
      "Epoch 28: val_loss did not improve from 2.60021\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.3806 - loss: 2.3427 - val_accuracy: 0.2550 - val_loss: 3.2034\n",
      "Epoch 29/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3957 - loss: 2.3180\n",
      "Epoch 29: val_loss did not improve from 2.60021\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.3957 - loss: 2.3180 - val_accuracy: 0.3300 - val_loss: 2.6377\n",
      "Epoch 30/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4008 - loss: 2.2732\n",
      "Epoch 30: val_loss did not improve from 2.60021\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 25ms/step - accuracy: 0.4008 - loss: 2.2732 - val_accuracy: 0.3434 - val_loss: 2.6054\n",
      "Epoch 31/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4032 - loss: 2.2360\n",
      "Epoch 31: val_loss did not improve from 2.60021\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.4032 - loss: 2.2360 - val_accuracy: 0.3407 - val_loss: 2.6007\n",
      "Epoch 32/100\n",
      "\u001b[1m3858/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4051 - loss: 2.2162\n",
      "Epoch 32: val_loss did not improve from 2.60021\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.4051 - loss: 2.2162 - val_accuracy: 0.3518 - val_loss: 2.6237\n",
      "Epoch 33/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4234 - loss: 2.1995\n",
      "Epoch 33: val_loss improved from 2.60021 to 2.57540, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.4234 - loss: 2.1995 - val_accuracy: 0.3456 - val_loss: 2.5754\n",
      "Epoch 34/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4202 - loss: 2.1616\n",
      "Epoch 34: val_loss did not improve from 2.57540\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.4202 - loss: 2.1616 - val_accuracy: 0.3485 - val_loss: 2.6590\n",
      "Epoch 35/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4294 - loss: 2.1168\n",
      "Epoch 35: val_loss improved from 2.57540 to 2.42337, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 25ms/step - accuracy: 0.4294 - loss: 2.1168 - val_accuracy: 0.3883 - val_loss: 2.4234\n",
      "Epoch 36/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4373 - loss: 2.0892\n",
      "Epoch 36: val_loss did not improve from 2.42337\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 25ms/step - accuracy: 0.4373 - loss: 2.0892 - val_accuracy: 0.3699 - val_loss: 2.5196\n",
      "Epoch 37/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4445 - loss: 2.0789\n",
      "Epoch 37: val_loss did not improve from 2.42337\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.4445 - loss: 2.0789 - val_accuracy: 0.3841 - val_loss: 2.4501\n",
      "Epoch 38/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4599 - loss: 2.0266\n",
      "Epoch 38: val_loss did not improve from 2.42337\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 25ms/step - accuracy: 0.4599 - loss: 2.0266 - val_accuracy: 0.3689 - val_loss: 2.5498\n",
      "Epoch 39/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4584 - loss: 2.0224\n",
      "Epoch 39: val_loss did not improve from 2.42337\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.4584 - loss: 2.0224 - val_accuracy: 0.3860 - val_loss: 2.4804\n",
      "Epoch 40/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4601 - loss: 2.0035\n",
      "Epoch 40: val_loss did not improve from 2.42337\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.4601 - loss: 2.0035 - val_accuracy: 0.3386 - val_loss: 2.8223\n",
      "Epoch 41/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4675 - loss: 1.9737\n",
      "Epoch 41: val_loss did not improve from 2.42337\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.4675 - loss: 1.9737 - val_accuracy: 0.3878 - val_loss: 2.4899\n",
      "Epoch 42/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4760 - loss: 1.9505\n",
      "Epoch 42: val_loss improved from 2.42337 to 2.38765, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.4760 - loss: 1.9505 - val_accuracy: 0.4070 - val_loss: 2.3876\n",
      "Epoch 43/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4853 - loss: 1.9162\n",
      "Epoch 43: val_loss improved from 2.38765 to 2.36473, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.4853 - loss: 1.9162 - val_accuracy: 0.4058 - val_loss: 2.3647\n",
      "Epoch 44/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4775 - loss: 1.9035\n",
      "Epoch 44: val_loss improved from 2.36473 to 2.34896, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.4775 - loss: 1.9035 - val_accuracy: 0.4097 - val_loss: 2.3490\n",
      "Epoch 45/100\n",
      "\u001b[1m3858/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4886 - loss: 1.8725\n",
      "Epoch 45: val_loss did not improve from 2.34896\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.4886 - loss: 1.8725 - val_accuracy: 0.3911 - val_loss: 2.4332\n",
      "Epoch 46/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4887 - loss: 1.8758\n",
      "Epoch 46: val_loss improved from 2.34896 to 2.31832, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 25ms/step - accuracy: 0.4887 - loss: 1.8758 - val_accuracy: 0.4204 - val_loss: 2.3183\n",
      "Epoch 47/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5052 - loss: 1.8376\n",
      "Epoch 47: val_loss did not improve from 2.31832\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.5052 - loss: 1.8376 - val_accuracy: 0.4060 - val_loss: 2.3956\n",
      "Epoch 48/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5049 - loss: 1.8192\n",
      "Epoch 48: val_loss did not improve from 2.31832\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.5049 - loss: 1.8192 - val_accuracy: 0.3889 - val_loss: 2.5171\n",
      "Epoch 49/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5116 - loss: 1.8064\n",
      "Epoch 49: val_loss did not improve from 2.31832\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.5116 - loss: 1.8064 - val_accuracy: 0.4066 - val_loss: 2.3999\n",
      "Epoch 50/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5205 - loss: 1.7789\n",
      "Epoch 50: val_loss did not improve from 2.31832\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.5205 - loss: 1.7789 - val_accuracy: 0.4091 - val_loss: 2.4231\n",
      "Epoch 51/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5201 - loss: 1.7693\n",
      "Epoch 51: val_loss improved from 2.31832 to 2.29118, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.5201 - loss: 1.7693 - val_accuracy: 0.4406 - val_loss: 2.2912\n",
      "Epoch 52/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5279 - loss: 1.7414\n",
      "Epoch 52: val_loss did not improve from 2.29118\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.5279 - loss: 1.7414 - val_accuracy: 0.4332 - val_loss: 2.2938\n",
      "Epoch 53/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5257 - loss: 1.7318\n",
      "Epoch 53: val_loss did not improve from 2.29118\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.5257 - loss: 1.7318 - val_accuracy: 0.4058 - val_loss: 2.4657\n",
      "Epoch 54/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5258 - loss: 1.6992\n",
      "Epoch 54: val_loss did not improve from 2.29118\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.5258 - loss: 1.6992 - val_accuracy: 0.4214 - val_loss: 2.3364\n",
      "Epoch 55/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5342 - loss: 1.6871\n",
      "Epoch 55: val_loss improved from 2.29118 to 2.27234, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.5342 - loss: 1.6870 - val_accuracy: 0.4465 - val_loss: 2.2723\n",
      "Epoch 56/100\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5357 - loss: 1.6701\n",
      "Epoch 56: val_loss improved from 2.27234 to 2.23585, saving model to models/custom_model/custom_model.keras\n",
      "\u001b[1m3859/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 25ms/step - accuracy: 0.5357 - loss: 1.6701 - val_accuracy: 0.4461 - val_loss: 2.2359\n",
      "Epoch 57/100\n",
      "\u001b[1m3478/3859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.5406 - loss: 1.6510"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(\"Starting custom models learning script.\\n\")\n",
    "    remove_last_generated_models()\n",
    "    \n",
    "    image_size = (224, 224)\n",
    "    batch_size = 4\n",
    "    labels_number = 120\n",
    "    \n",
    "    dataset_train = get_dataset(CROPPED_IMAGES_PATH, image_size, batch_size, validation_split=0.25,\n",
    "                                data_type='training')\n",
    "    dataset_val = get_dataset(CROPPED_IMAGES_PATH, image_size, batch_size, validation_split=0.25,\n",
    "                              data_type='validation')\n",
    "    dataset_test = get_dataset(CROPPED_IMAGES_PATH, image_size, batch_size, data_type=None)\n",
    "    \n",
    "    best_layers_parameters = {}\n",
    "\n",
    "    \n",
    "    # MODEL HYPEROPTIMIZATION\n",
    "    results = []\n",
    "    for hyperparameters in [\n",
    "        {\"name\": \"1_intermediate_layers\", \"parameters\": {\"number_of_intermediate_layers\": 1}},\n",
    "        {\"name\": \"2_intermediate_layers\", \"parameters\": {\"number_of_intermediate_layers\": 2}},\n",
    "        {\"name\": \"3_intermediate_layers\", \"parameters\": {\"number_of_intermediate_layers\": 3}},\n",
    "        {\"name\": \"4_intermediate_layers\", \"parameters\": {\"number_of_intermediate_layers\": 4}},\n",
    "        {\"name\": \"5_intermediate_layers\", \"parameters\": {\"number_of_intermediate_layers\": 5}}\n",
    "    ]:\n",
    "        print(f\"\\nTesting now the parameters:{hyperparameters[\"parameters\"]}.\\n\")\n",
    "        model = create_model(input_shape=image_size + (3,), labels_number=labels_number,\n",
    "                             **hyperparameters[\"parameters\"])\n",
    "        results.append(get_results_of_model(model, dataset_train, dataset_val, dataset_test,\n",
    "                                            hyperparameters[\"parameters\"]))\n",
    "        \n",
    "    sorted_results = sorted(results, key=lambda x: x[\"val_accuracy\"], reverse=True)\n",
    "    best_layers_parameters[\"number_of_intermediate_layers\"] = get_best_parameter(sorted_results,\n",
    "                                                                                 \"number_of_intermediate_layers\")\n",
    "    display_results(sorted_results, \"number_of_intermediate_layers\")\n",
    "    \n",
    "    results = []\n",
    "    for hyperparameters in [\n",
    "        {\"name\": \"kernel_layer_size_1\", \"parameters\": {\"kernel_size\": (1, 1)}},\n",
    "        {\"name\": \"kernel_layer_size_2\", \"parameters\": {\"kernel_size\": (2, 2)}},\n",
    "        {\"name\": \"kernel_layer_size_3\", \"parameters\": {\"kernel_size\": (3, 3)}},\n",
    "        {\"name\": \"kernel_layer_size_4\", \"parameters\": {\"kernel_size\": (4, 4)}},\n",
    "        {\"name\": \"kernel_layer_size_5\", \"parameters\": {\"kernel_size\": (5, 5)}}\n",
    "    ]:\n",
    "        print(f\"Testing now the parameters:{hyperparameters[\"parameters\"]}.\\n\")\n",
    "        model = create_model(input_shape=image_size + (3,), labels_number=labels_number,\n",
    "                             number_of_intermediate_layers=best_layers_parameters[\"number_of_intermediate_layers\"],\n",
    "                             **hyperparameters[\"parameters\"])\n",
    "        keras.backend.clear_session()\n",
    "        results.append(get_results_of_model(model, dataset_train, dataset_val, dataset_test,\n",
    "                                            hyperparameters[\"parameters\"]))\n",
    "        \n",
    "    sorted_results = sorted(results, key=lambda x: x[\"val_accuracy\"], reverse=True)\n",
    "    best_layers_parameters[\"kernel_size\"] = get_best_parameter(sorted_results, \"kernel_size\")\n",
    "    display_results(sorted_results, \"kernel_size\")\n",
    "    \n",
    "    results = []\n",
    "    for hyperparameters in [\n",
    "        {\"name\": \"dropout_rate_0.1\", \"parameters\": {\"dropout_rate\": 0.1}},\n",
    "        {\"name\": \"dropout_rate_0.2\", \"parameters\": {\"dropout_rate\": 0.2}},\n",
    "        {\"name\": \"dropout_rate_0.3\", \"parameters\": {\"dropout_rate\": 0.3}},\n",
    "        {\"name\": \"dropout_rate_0.4\", \"parameters\": {\"dropout_rate\": 0.4}},\n",
    "        {\"name\": \"dropout_rate_0.5\", \"parameters\": {\"dropout_rate\": 0.5}},\n",
    "        {\"name\": \"dropout_rate_0.6\", \"parameters\": {\"dropout_rate\": 0.6}},\n",
    "        {\"name\": \"dropout_rate_0.7\", \"parameters\": {\"dropout_rate\": 0.7}},\n",
    "        {\"name\": \"dropout_rate_0.8\", \"parameters\": {\"dropout_rate\": 0.8}},\n",
    "    ]:\n",
    "        print(f\"Testing now the parameters:{hyperparameters[\"parameters\"]}.\\n\")\n",
    "        model = create_model(input_shape=image_size + (3,), labels_number=labels_number,\n",
    "                             number_of_intermediate_layers=best_layers_parameters[\"number_of_intermediate_layers\"],\n",
    "                             kernel_size=best_layers_parameters[\"kernel_size\"], **hyperparameters[\"parameters\"])\n",
    "        results.append(get_results_of_model(model, dataset_train, dataset_val, dataset_test,\n",
    "                                            hyperparameters[\"parameters\"]))\n",
    "        \n",
    "    sorted_results = sorted(results, key=lambda x: x[\"val_accuracy\"], reverse=True)\n",
    "    best_layers_parameters[\"dropout_rate\"] = get_best_parameter(sorted_results, \"dropout_rate\")\n",
    "    display_results(sorted_results, \"dropout_rate\")\n",
    "\n",
    "    \n",
    "    # COMPILATION HYPEROPTIMIZATION\n",
    "    results = []\n",
    "    for hyperparameters in [\n",
    "        {\"name\": \"rmsprop_optimizer\", \"parameters\": {\"optimizer\": \"rmsprop\"}},\n",
    "        {\"name\": \"adam_optimizer\", \"parameters\": {\"optimizer\": \"adam\"}},\n",
    "        {\"name\": \"adamw_optimizer\", \"parameters\": {\"optimizer\": \"adamw\"}},\n",
    "        {\"name\": \"sgd_optimizer\", \"parameters\": {\"optimizer\": \"sgd\"}},\n",
    "        {\"name\": \"sgd_nesterov_optimizer\", \"parameters\": {\"optimizer\": \"sgdn\"}},\n",
    "    ]:\n",
    "        print(f\"Testing now the parameters:{hyperparameters[\"parameters\"]}.\\n\")\n",
    "        model = create_model(input_shape=image_size + (3,), labels_number=labels_number,\n",
    "                             number_of_intermediate_layers=best_layers_parameters[\"number_of_intermediate_layers\"],\n",
    "                             kernel_size=best_layers_parameters[\"kernel_size\"],\n",
    "                             dropout_rate=best_layers_parameters[\"dropout_rate\"],\n",
    "                             **hyperparameters[\"parameters\"])\n",
    "        results.append(get_results_of_model(model, dataset_train, dataset_val, dataset_test,\n",
    "                                            hyperparameters[\"parameters\"]))\n",
    "        \n",
    "    sorted_results = sorted(results, key=lambda x: x[\"val_accuracy\"], reverse=True)\n",
    "    best_layers_parameters[\"optimizer\"] = get_best_parameter(sorted_results, \"optimizer\")\n",
    "    display_results(sorted_results, \"optimizer\")\n",
    "    \n",
    "    results = []\n",
    "    for hyperparameters in [\n",
    "        {\"name\": \"learning_rate_0.00001\", \"parameters\": {\"learning_rate\": 0.00001}},\n",
    "        {\"name\": \"learning_rate_0.00005\", \"parameters\": {\"learning_rate\": 0.00005}},\n",
    "        {\"name\": \"learning_rate_0.0001\", \"parameters\": {\"learning_rate\": 0.0001}},\n",
    "        {\"name\": \"learning_rate_0.0005\", \"parameters\": {\"learning_rate\": 0.0005}},\n",
    "        {\"name\": \"learning_rate_0.001\", \"parameters\": {\"learning_rate\": 0.001}},\n",
    "        {\"name\": \"learning_rate_0.005\", \"parameters\": {\"learning_rate\": 0.005}}\n",
    "    ]:\n",
    "        print(f\"Testing now the parameters:{hyperparameters[\"parameters\"]}.\\n\")\n",
    "        model = create_model(input_shape=image_size + (3,), labels_number=labels_number,\n",
    "                             number_of_intermediate_layers=best_layers_parameters[\"number_of_intermediate_layers\"],\n",
    "                             kernel_size=best_layers_parameters[\"kernel_size\"],\n",
    "                             dropout_rate=best_layers_parameters[\"dropout_rate\"],\n",
    "                             optimizer=best_layers_parameters[\"optimizer\"],\n",
    "                             **hyperparameters[\"parameters\"])\n",
    "        results.append(get_results_of_model(model, dataset_train, dataset_val, dataset_test,\n",
    "                                            hyperparameters[\"parameters\"]))\n",
    "        \n",
    "    sorted_results = sorted(results, key=lambda x: x[\"val_accuracy\"], reverse=True)\n",
    "    best_layers_parameters[\"learning_rate\"] = get_best_parameter(sorted_results, \"learning_rate\")\n",
    "    display_results(sorted_results, \"learning_rate\")\n",
    "\n",
    "    # EXECUTION HYPEROPTIMIZATION\n",
    "    results = []\n",
    "    for hyperparameters in [\n",
    "        {\"name\": \"epoch_25\", \"parameters\": {\"epoch\": 25, \"with_early_stopping\": False}},\n",
    "        {\"name\": \"epoch_50\", \"parameters\": {\"epoch\": 50, \"with_early_stopping\": False}},\n",
    "        {\"name\": \"epoch_75\", \"parameters\": {\"epoch\": 75, \"with_early_stopping\": False}},\n",
    "        {\"name\": \"epoch_100\", \"parameters\": {\"epoch\": 100, \"with_early_stopping\": False}},\n",
    "        {\"name\": \"early_stopping\", \"parameters\": {\"epoch\": 100, \"with_early_stopping\": True}},\n",
    "    ]:\n",
    "        print(f\"Testing now the parameters:{hyperparameters[\"parameters\"]}.\\n\")\n",
    "        model = create_model(input_shape=image_size + (3,), labels_number=labels_number,\n",
    "                             number_of_intermediate_layers=best_layers_parameters[\"number_of_intermediate_layers\"],\n",
    "                             kernel_size=best_layers_parameters[\"kernel_size\"],\n",
    "                             dropout_rate=best_layers_parameters[\"dropout_rate\"],\n",
    "                             optimizer=best_layers_parameters[\"optimizer\"],\n",
    "                             learning_rate=best_layers_parameters[\"learning_rate\"])\n",
    "        results.append(get_results_of_model(model, dataset_train, dataset_val, dataset_test,\n",
    "                                            hyperparameters[\"parameters\"], **hyperparameters[\"parameters\"]))\n",
    "        \n",
    "    sorted_results = sorted(results, key=lambda x: x[\"val_accuracy\"], reverse=True)\n",
    "    best_layers_parameters[\"epoch\"] = get_best_parameter(sorted_results, \"epoch\")\n",
    "    best_layers_parameters[\"with_early_stopping\"] = get_best_parameter(sorted_results, \"with_early_stopping\")\n",
    "    display_results(sorted_results, \"epoch\")\n",
    "    \n",
    "    results = []\n",
    "    for hyperparameters in [\n",
    "        {\"name\": \"batch_size_4\", \"parameters\": {\"batch_size\": 1}},\n",
    "        {\"name\": \"batch_size_8\", \"parameters\": {\"batch_size\": 2}},\n",
    "        {\"name\": \"batch_size_16\", \"parameters\": {\"batch_size\": 4}},\n",
    "        {\"name\": \"batch_size_32\", \"parameters\": {\"batch_size\": 8}},\n",
    "    ]:\n",
    "        print(f\"Testing now the parameters:{hyperparameters[\"parameters\"]}.\\n\")\n",
    "        model = create_model(input_shape=image_size + (3,), labels_number=labels_number,\n",
    "                             number_of_intermediate_layers=best_layers_parameters[\"number_of_intermediate_layers\"],\n",
    "                             kernel_size=best_layers_parameters[\"kernel_size\"],\n",
    "                             dropout_rate=best_layers_parameters[\"dropout_rate\"],\n",
    "                             optimizer=best_layers_parameters[\"optimizer\"],\n",
    "                             learning_rate=best_layers_parameters[\"learning_rate\"])\n",
    "        \n",
    "        new_batch_size = hyperparameters[\"parameters\"][\"batch_size\"]\n",
    "        dataset_train = get_dataset(CROPPED_IMAGES_PATH, image_size, new_batch_size, validation_split=0.25,\n",
    "                                    data_type='training')\n",
    "        dataset_val = get_dataset(CROPPED_IMAGES_PATH, image_size, new_batch_size, validation_split=0.25,\n",
    "                                  data_type='validation')\n",
    "        dataset_test = get_dataset(CROPPED_IMAGES_PATH, image_size, new_batch_size, data_type=None)\n",
    "        \n",
    "        results.append(get_results_of_model(model, dataset_train, dataset_val, dataset_test, \n",
    "                                            hyperparameters[\"parameters\"], epoch=best_layers_parameters[\"epoch\"],\n",
    "                                            with_early_stopping=best_layers_parameters[\"with_early_stopping\"],\n",
    "                                            batch_size=new_batch_size))\n",
    "        \n",
    "    sorted_results = sorted(results, key=lambda x: x[\"val_accuracy\"], reverse=True)\n",
    "    best_layers_parameters[\"batch_size\"] = get_best_parameter(sorted_results, \"batch_size\")\n",
    "    display_results(sorted_results, \"batch_size\")\n",
    "    \n",
    "    print(f\"Hyperoptimization now done. Best hyperparameters found:{best_layers_parameters}.\\n\")\n",
    "    \n",
    "    print(\"Custom models learning script finished.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
